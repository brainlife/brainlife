version: "3"

services:

  redis:
    container_name: brainlife_redis
    networks:
      - brainlife
    image: redis:7.0.2
    healthcheck:
      test: [ "CMD", "redis-cli", "--raw", "incr", "ping" ]
      interval: 10s
      timeout: 10s
      retries: 5
    ports:
      - 6379:6379

  influxdb:
    container_name: brainlife_influxdb
    networks:
      - brainlife
    image: influxdb:2.0
    volumes:
      - ./volumes/influxdb/:/var/lib/influxdb2/
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=brainlife
      - DOCKER_INFLUXDB_INIT_PASSWORD=brainlife123
      - DOCKER_INFLUXDB_INIT_ORG=brainlife
      - DOCKER_INFLUXDB_INIT_BUCKET=brainlife
      - DOCKER_INFLUXDB_INIT_RETENTION=1w
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=mydevtoken
    healthcheck:
      test: [ "CMD", "curl", "influxdb:8086/api/v2/ping" ]
      interval: 1m
      timeout: 10s
      retries: 5

  mongodb:
    container_name: brainlife_mongodb
    networks:
      - brainlife
    image: mongo:4.4
    volumes:
      - mongodata:/data/db
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongo localhost:27017/test --quiet
      interval: 10s
      timeout: 10s
      retries: 5
    ports:
      - 27017:27017

  rabbitmq:
    container_name: brainlife_rabbitmq
    networks:
      - brainlife
    image: rabbitmq:3.10.5-management
    environment:
      - RABBITMQ_DEFAULT_VHOST=brainlife
    healthcheck:
      test: rabbitmq-diagnostics -q ping
      interval: 15s
      timeout: 10s
      retries: 5
    volumes:
      - ./volumes/rabbitmq/:/var/lib/rabbitmq/
    ports:
      - '5672:5672'
      - '15672:15672'

  nginx:
    container_name: brainlife_nginx
    networks:
      - brainlife
    image: nginx:1.18
    restart: always
    depends_on:
      amaretti-api:
        condition: service_healthy
      warehouse-api:
        condition: service_healthy
      auth-api:
        condition: service_healthy
      warehouse-ui:
        condition: service_healthy
      auth-ui:
        condition: service_healthy
    volumes:
      - ./config/nginx/home:/home
      - ./ui:/ui
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf
    ports:
      - 8080:80

  auth-api-generate_keys:
    container_name: brainlife_auth-api_generate_keys
    build: ./auth
    image: brainlife_auth
    networks:
      - brainlife
    volumes:
      - ./:/brainlife-dev
      - ./auth:/app
      - /app/node_modules
    depends_on:
      mongodb:
        condition: service_healthy
    restart: 'no'
    command: /brainlife-dev/scripts/generate_keys.sh

  auth-api:
    container_name: brainlife_auth-api
    networks:
      - brainlife
    build: ./auth
    image: brainlife_auth
    volumes:
      - ./:/brainlife-dev
      - ./auth:/app
      - /app/node_modules
    ports:
      - 28000:8000
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      auth-api-generate_keys:
        condition: service_completed_successfully
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]

  event-api:
    container_name: brainlife_event-api
    networks:
      - brainlife
    build: ./event
    image: brainlife_event
    volumes:
      - ./event:/app
    depends_on:
      mongodb:
        condition: service_healthy
      auth-api:
        condition: service_healthy
      auth-api-generate_keys:
        condition: service_completed_successfully
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/health" ]

  amaretti-api:
    container_name: brainlife_amaretti-api
    networks:
      - brainlife
    build: ./amaretti
    image: brainlife_amaretti
    volumes:
      - ./amaretti:/app
    depends_on:
      event-api:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/health" ]
    command: pm2 start ./api/amaretti.js --attach --watch --ignore-watch "ui **/node_modules"

  amaretti-task-rule:
    container_name: brainlife_amaretti-task-rule
    networks:
      - brainlife
    build: ./amaretti
    image: brainlife_amaretti
    volumes:
      - ./amaretti:/app
    depends_on:
      event-api:
        condition: service_healthy
    command: pm2 start ./bin/task.js --attach --watch --ignore-watch "ui **/node_modules"

  amaretti-task-ui:
    container_name: brainlife_amaretti-task-ui
    networks:
      - brainlife
    build: ./amaretti
    image: brainlife_amaretti
    volumes:
      - ./amaretti:/app
    depends_on:
      event-api:
        condition: service_healthy
    command: pm2 start ./bin/task.js --attach --watch --ignore-watch "ui **/node_modules" -- --nonice

  # this runs synchronously (how?)
  #  amaretti-resource:
  #    container_name: brainlife_amaretti-resource
  #    networks:
  #      - brainlife
  #    build: ./amaretti
  #    image: brainlife_amaretti
  #    volumes:
  #      - ./amaretti:/app
  #    depends_on:
  #      event-api:
  #        condition: service_healthy
  #    command: pm2 start ./bin/resource.js --attach --watch --ignore-watch "ui **/node_modules"

  #  amaretti-workdir:
  #    container_name: brainlife_amaretti-workdir
  #    networks:
  #      - brainlife
  #    build: ./amaretti
  #    image: brainlife_amaretti
  #    volumes:
  #      - ./amaretti:/app
  #    depends_on:
  #      event-api:
  #        condition: service_healthy
  #    command: pm2 start ./bin/remove_workdirs.js --attach --watch --ignore-watch "ui **/node_modules"

  warehouse-api:
    container_name: brainlife_warehouse-api
    networks:
      - brainlife
    build: ./warehouse
    image: brainlife_warehouse
    volumes:
      - ./warehouse:/app
      - ./volumes/archive:/archive:ro
      - ./volumes/secondary:/secondary:ro
      - ./volumes/datalad:/datalad
    depends_on:
      amaretti-api:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/health" ]
      interval: 15s
      timeout: 10s
      retries: 5
    command: pm2 start ./api/warehouse.js --attach --watch --ignore-watch "ui **/node_modules"
    environment:
      - DATALAD_DIRECTORY=/datalad

  warehouse-rule:
    container_name: brainlife_warehouse-rule
    networks:
      - brainlife
    build: ./warehouse
    image: brainlife_warehouse
    volumes:
      - ./warehouse:/app
    depends_on:
      amaretti-api:
        condition: service_healthy
    command: pm2 start ./bin/rule_handler.js --attach --watch --ignore-watch "ui **/node_modules"

  warehouse-events:
    container_name: brainlife_warehouse-events
    networks:
      - brainlife
    build: ./warehouse
    image: brainlife_warehouse
    volumes:
      - ./warehouse:/app
    depends_on:
      amaretti-api:
        condition: service_healthy
    command: pm2 start ./bin/event_handler.js --attach --watch --ignore-watch "ui **/node_modules"

  auth-ui:
    container_name: brainlife_auth-ui
    networks:
      - brainlife
    build: ./auth/ui
    image: brainlife_auth-ui
    volumes:
      - ./auth/ui:/ui
    depends_on:
      auth-api:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:3000" ]

  warehouse-ui:
    container_name: brainlife_warehouse-ui
    networks:
      - brainlife
    build: ./warehouse/ui
    image: brainlife_warehouse-ui
    volumes:
      - ./warehouse/ui:/app
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080" ]
      interval: 15s
      timeout: 10s
      retries: 10

  archive:
    container_name: brainlife_archive
    networks:
      - brainlife
    build: ./archive
    image: brainlife_archive
    privileged: true # needed by singularity
    depends_on:
      auth-api-generate_keys:
        condition: service_completed_successfully
    volumes:
      - ./archive/.ssh:/home/brainlife/.ssh:ro
      - ./volumes/archive:/archive
      - ./volumes/stage:/stage
      - ./volumes/secondary:/secondary
      - ./volumes/singularity:/home/brainlife/.singularity
      - /etc/timezone:/etc/timezone # needed by singularity
      - /etc/localtime:/etc/localtime # needed by singularity

  upload:
    container_name: brainlife_upload
    networks:
      - brainlife
    build: ./upload
    image: brainlife_upload
    privileged: true # needed by singularity
    volumes:
      - ./upload/.ssh:/home/brainlife/.ssh:ro
      - ./volumes/upload:/upload
      - ./volumes/ezbids:/ezbids
      - ./volumes/singularity:/home/brainlife/.singularity
      - /etc/timezone:/etc/timezone # needed by singularity
      - /etc/localtime:/etc/localtime # needed by singularity

  compute:
    container_name: brainlife_compute
    networks:
      - brainlife
    build: ./compute
    image: brainlife_compute
    privileged: true # needed by singularity
    volumes:
      - ./compute/.ssh:/home/brainlife/.ssh:ro
      - ./volumes/compute:/scratch
      - ./volumes/singularity:/home/brainlife/.singularity
      - /etc/timezone:/etc/timezone # needed by singularity
      - /etc/localtime:/etc/localtime # needed by singularity

  vis:
    container_name: brainlife_vis
    networks:
      - brainlife
    build: ./vis
    image: brainlife_vis
    privileged: true # needed by docker
    volumes:
      - ./volumes/vis-scratch:/scratch
      - ./volumes/vis-docker:/var/lib/docker
      - ./volumes/singularity:/root/.singularity
      - /etc/timezone:/etc/timezone # needed by singularity
      - /etc/localtime:/etc/localtime # needed by singularity
      - /tmp/.X11-unix:/tmp/.X11-unix:ro # needs xserver on host (XQuartz for mac)
      - /var/run/docker.sock:/var/run/docker.sock # let it use the host docker engine (only way I found so far)
    environment:
      - BRAINLIFE_HOSTSCRATCH=${PWD}/volumes/vis-scratch
    extra_hosts:
      - "host.docker.internal:host-gateway" # setup.js needs access to the host

volumes:
  mongodata:


networks:
  brainlife:
    name: brainlife
    # external: true # uncomment this if you want to use existing network
    driver_opts:
      com.docker.network.bridge.host_binding_ipv4: "127.0.0.1"
      # change to 0.0.0.0 or to your host IP if you want to access brainlife
      # from outside of the docker host
